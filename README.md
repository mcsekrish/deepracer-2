# AWS Deepracer
This repo stores the reward function of AWS Deepracer and the hyperparameter configuration and the trained result. 


| Model | Reward                                                                           | Environment simulation                          | Action space                                            | Hyperparameter                                                                                                                                                                                                  | Evaluation - 2022 re:Invent Championship  - Counterclockwise | Trained             |
|-------|----------------------------------------------------------------------------------|-------------------------------------------------|---------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|---------------------|
| 1     | follow center line                                                               | re:Invent 2018  - Counterclockwise              | Speed: [ 0.5 : 1 ] m/s Steering angle: [ -30 : 30 ] °   | Entropy: 0.01, Gradient descent batch size: 64, Learning rate: 0.0003, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10 | 00:43.065                                                    | 01:00:00 / 01:00:00 |
| 2     | stay inside the two borders of the track                                         | re:Invent 2018 - Counterclockwise               | Speed: [ 0.5 : 1 ] m/s Steering angle: [ -30 : 30 ] °   | Entropy: 0.01, Gradient descent batch size: 64, Learning rate: 0.0003, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10 | 00:49.672                                                    | 01:00:00 / 01:00:00 |
| 3     | stay inside the two borders of the track and follow center line and higher speed | 2022 re:Invent Championship  - Counterclockwise | Speed: [ 0.5 : 2 ] m/s Steering angle: [ -30 : 30 ] °   | Entropy: 0.03, Gradient descent batch size: 64, Learning rate: 0.001, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10  | 00:38.402                                                    | 00:40:00 / 00:40:00 |
| 4     | same as above but different values                                               | 2022 re:Invent Championship  - Counterclockwise | Speed: [ 0.5 : 1.5 ] m/s Steering angle: [ -30 : 30 ] ° | Entropy: 0.03, Gradient descent batch size: 64, Learning rate: 0.0005, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10 | 00:35.137                                                    | 00:45:00 / 00:45:00 |
| 5     | using waypoints and heading to make the car point in the right direction         | 2022 re:Invent Championship  - Counterclockwise | Speed: [ 0.5 : 1.5 ] m/s Steering angle: [ -30 : 30 ] ° | Entropy: 0.03, Gradient descent batch size: 64, Learning rate: 0.0005, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10 | 00:29.659                                                    | 01:00:00 / 01:00:00 |
| 6     | same as above + penalize if off track / crashed / reversed                       | 2022 re:Invent Championship  - Counterclockwise | Speed: [ 0.5 : 2 ] m/s Steering angle: [ -30 : 30 ] °   | Entropy: 0.03, Gradient descent batch size: 64, Learning rate: 0.0005, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10 | 00:26.663                                                    | 00:30:00 / 00:30:00 |
| 7     | same as above + check steering angle when near to off track                      | 2022 re:Invent Championship  - Counterclockwise | Speed: [ 0.5 : 2 ] m/s Steering angle: [ -30 : 30 ] °   | Entropy: 0.03, Gradient descent batch size: 64, Learning rate: 0.0005, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10 | 00:26.462                                                    | 00:30:00 / 00:30:00 |
| 8     | same as above but different values                                               | 2022 re:Invent Championship  - Counterclockwise | Speed: [ 0.5 : 2.5 ] m/s Steering angle: [ -30 : 30 ] ° | Entropy: 0.1, Gradient descent batch size: 64, Learning rate: 0.0005, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10  | 00:26.339                                                    | 01:00:00 / 01:00:00 |
| 9     | same as above + follow center line                                               | 2022 re:Invent Championship  - Counterclockwise | Speed: [ 0.5 : 2 ] m/s Steering angle: [ -30 : 30 ] °   | Entropy: 0.05, Gradient descent batch size: 64, Learning rate: 0.0005, Discount factor: 0.999, Loss type: Huber, Number of experience episodes between each policy-updating iteration: 20, Number of epochs: 10 | 00:28.529                                                    | 00:30:00 / 00:30:00 |